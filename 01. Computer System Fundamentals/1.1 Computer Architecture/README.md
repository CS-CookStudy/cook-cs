# 📘 1.1 컴퓨터 구조

# 1.1-1 CPU, 메모리, 저장 위치의 이해

## 1. 구성 요소의 역할 개요

### CPU (Central Processing Unit)

CPU는 컴퓨터의 중심 연산 장치로서, 명령어를 해석하고 실행하는 역할을 담당한다. 내부에는 연산을 처리하는 ALU, 제어 흐름을 조정하는 제어 유닛, 임시 저장 공간인 레지스터가 포함되어 있다.

* **레지스터(Register)**: CPU 내부의 초고속 임시 저장장치로, 연산 대상이나 연산 결과를 저장한다.
* **ALU(Arithmetic Logic Unit)**: 산술 연산(덧셈, 뺄셈 등)과 논리 연산(AND, OR 등)을 수행한다.
* **제어 유닛(Control Unit)**: 명령어를 해석하고, 연산 흐름을 제어하며, 레지스터와 ALU, 메모리 간의 데이터 흐름을 조정한다.
* **명령어 사이클**: 명령어는 보통 Fetch(인출) → Decode(해석) → Execute(실행)의 과정을 거친다.

현대의 CPU는 하나 이상의 코어(Core)로 구성된다. 각 코어는 독립적으로 명령어를 처리할 수 있는 단위를 의미하며, 멀티코어 구조는 병렬 처리를 가능하게 한다. 또한 파이프라이닝 기법을 활용하여 하나의 명령어가 실행되는 동안 다른 명령어를 동시에 준비함으로써 성능을 향상시킨다.

> 용어 설명:
>
> * **명령어 사이클**: 하나의 명령어가 CPU에 의해 처리되는 일련의 과정
> * **파이프라이닝(Pipelining)**: 명령어를 여러 단계로 분리하여 동시에 처리하는 성능 향상 기법
> * **멀티코어**: 하나의 CPU 칩에 여러 개의 처리 유닛(코어)을 포함한 구조

## 2. 메인 메모리 (RAM: Random Access Memory)

RAM은 휘발성 메모리로, 전원이 꺼지면 저장된 내용이 사라진다. 실행 중인 프로그램의 명령어와 데이터를 임시로 저장하며, CPU가 직접 접근하여 데이터를 읽고 쓸 수 있는 공간이다.

* **주 기억장치로서의 역할**: 현재 실행 중인 코드, 변수, 스택 등의 데이터를 저장한다.
* **속도**: 저장장치보다 훨씬 빠르며, CPU와의 직접 연결을 통해 낮은 지연 시간으로 데이터를 주고받는다.
* **버스(Bus)**: RAM과 CPU는 주소 버스와 데이터 버스를 통해 연결되며, 이를 통해 데이터가 전달된다.

현대 시스템에서는 메모리 채널을 병렬로 구성할 수 있으며, 대표적으로 싱글 채널과 듀얼 채널 방식이 존재한다. 듀얼 채널 구성은 메모리 대역폭을 두 배로 확장하여 메모리 접근 성능을 향상시킨다.

> 용어 설명:
>
> * **휘발성 메모리**: 전원이 꺼지면 저장된 정보가 사라지는 메모리
> * **버스(Bus)**: 컴퓨터 내부에서 데이터나 주소를 전달하는 전송 통로
> * **메모리 채널**: CPU와 메모리 간 데이터 통신 경로로, 여러 채널이 병렬로 구성되면 처리 속도가 증가한다

## 3. 저장장치 (Storage)

저장장치는 비휘발성 메모리로, 운영체제, 응용 프로그램, 파일 등 영구적인 데이터를 저장하는 공간이다. 대표적으로 HDD(Hard Disk Drive)와 SSD(Solid State Drive)가 있다.

* **HDD**: 자기 디스크를 회전시켜 데이터를 읽고 쓰는 방식으로, 상대적으로 저렴하지만 기계적 움직임으로 인해 속도가 느리다.
* **SSD**: NAND 플래시 메모리를 이용해 데이터를 저장하며, 기계적 부품이 없어 빠르고 내구성이 높다. 다만 용량 대비 가격이 비싸다.

저장장치는 RAM보다 속도가 현저히 느리기 때문에, 프로그램 실행 시 저장장치에 있는 데이터를 RAM으로 먼저 로딩한 후, CPU가 RAM에서 직접 명령어와 데이터를 처리하는 구조를 따른다.

> 용어 설명:
>
> * **비휘발성 메모리**: 전원이 꺼져도 데이터가 유지되는 저장 장치
> * **플래시 메모리(NAND)**: 전기적으로 데이터를 지우고 다시 쓸 수 있는 비휘발성 저장 기술

## 4. 전체 흐름 구조 (폰 노이만 구조 기반)

현대 컴퓨터는 기본적으로 폰 노이만 구조를 따른다. 이는 명령어와 데이터를 하나의 메모리 공간에 저장하고, CPU가 순차적으로 이를 가져와 처리하는 방식이다.

### 처리 흐름 요약

1. 프로그램은 저장장치(SSD/HDD)에 저장되어 있다.
2. 사용자가 프로그램을 실행하면, 운영체제가 해당 명령어와 데이터를 RAM으로 로드한다.
3. CPU는 RAM에서 명령어를 Fetch → Decode → Execute의 사이클로 처리한다.
4. 결과는 다시 RAM이나 저장장치로 저장된다.

이러한 구조에서 RAM은 속도와 유연성 측면에서 CPU와 저장장치 사이의 중간 완충지대 역할을 수행한다. 반면 저장장치는 대용량 데이터를 영구 보관하는 역할에 중점을 둔다.

이처럼 CPU, RAM, 저장장치는 각기 다른 특성과 속도를 가지며, 계층적인 구조로 결합되어 전체 컴퓨팅 시스템의 효율적인 동작을 가능하게 한다.

> 용어 설명:
>
> * **폰 노이만 구조**: 명령어와 데이터를 같은 메모리에 저장하고, CPU가 순차적으로 처리하는 컴퓨터 구조
> * **로드(Load)**: 저장된 데이터를 메모리(RAM)로 불러오는 작업


# 1.1-2 폰 노이만 구조 vs 하버드 구조

## 1. 폰 노이만 구조 (Von Neumann Architecture)

폰 노이만 구조는 현대 컴퓨터의 기본 아키텍처로, 명령어와 데이터를 **동일한 메모리 공간**에 저장하며, **단일 버스**를 통해 CPU가 이들을 순차적으로 처리하는 구조이다.

### 주요 특징
* **통합 메모리**: 명령어와 데이터가 같은 주소 공간에 존재
* **단일 버스**: 하나의 버스를 통해 명령어와 데이터가 전송되므로, 한 순간에는 하나만 접근 가능
* **순차 처리**: 명령어 인출(Fetch) → 해석(Decode) → 실행(Execute) 사이클을 순차적으로 수행
* **단순성**: 구조가 단순하고 설계 비용이 낮아 범용 컴퓨터에 적합

### 단점: 폰 노이만 병목 (Von Neumann Bottleneck)
* **동시 접근 불가**: 명령어와 데이터를 동시에 접근할 수 없음
* **버스 경합**: CPU의 처리 속도에 비해 메모리 접근 속도가 상대적으로 느려 병목 발생
* **성능 제약**: 명령어 인출과 데이터 처리가 순차적으로만 가능하여 처리량 한계

### 구조도
```
┌─────────────────────┐
│   통합 메모리 공간      │
│ ┌─────────────────┐ │
│ │   명령어 영역     │ │
│ ├─────────────────┤ │
│ │   데이터 영역     │ │
│ └─────────────────┘ │
└─────────────────────┘
           ↕
      [ 단일 버스 ]
           ↕
    ┌─────────────┐
    │     CPU     │
    │ ┌─────────┐ │
    │ │ 제어부   │ │
    │ ├─────────┤ │
    │ │  ALU    │ │
    │ ├─────────┤ │
    │ │레지스터  │ │
    │ └─────────┘ │
    └─────────────┘
```

## 2. 하버드 구조 (Harvard Architecture)

하버드 구조는 명령어와 데이터를 **물리적으로 완전히 분리된 메모리와 버스**에서 처리하는 구조이다. 각각 독립된 통로가 있으므로 **병렬 접근**이 가능하다.

### 주요 특징
* **분리된 메모리**: 명령어 메모리와 데이터 메모리가 물리적으로 분리
* **이중 버스**: 명령어 버스와 데이터 버스가 독립적으로 구성
* **병렬 처리**: CPU가 동시에 명령어를 인출하고 데이터를 읽거나 쓸 수 있음
* **예측 가능한 성능**: 명령어 접근이 데이터 접근에 방해받지 않아 실시간성 보장

### 장점
* **높은 처리량**: 명령어와 데이터 동시 접근으로 성능 향상
* **실시간성**: 예측 가능한 메모리 접근 시간
* **보안성**: 코드 주입 공격에 대한 방어력 향상 (명령어/데이터 영역 분리)

### 단점
* **높은 복잡도**: 설계 및 구현이 복잡
* **비용 증가**: 이중 메모리와 버스로 인한 하드웨어 비용 상승
* **메모리 효율성**: 명령어와 데이터 메모리 크기를 미리 정해야 하므로 유연성 부족

### 구조도
```
┌─────────────┐           ┌─────────────┐
│ 명령어 메모리 │           │ 데이터 메모리 │
└─────────────┘           └─────────────┘
       ↕                         ↕
  [명령어 버스]               [데이터 버스]
       ↕                         ↕
    ┌─────────────────────────────────┐
    │              CPU                │
    │ ┌─────────┐   ┌─────────────┐   │
    │ │명령어   │   │데이터 처리부 │   │
    │ │처리부   │   │             │   │
    │ └─────────┘   └─────────────┘   │
    │        ┌─────────┐              │
    │        │  ALU    │              │
    │        └─────────┘              │
    └─────────────────────────────────┘
```

## 3. 구조별 상세 비교

| 비교 항목 | 폰 노이만 구조 | 하버드 구조 |
|-----------|----------------|-------------|
| **메모리 구성** | 통합 메모리 (명령어/데이터 공유) | 분리된 메모리 (명령어/데이터 독립) |
| **버스 구조** | 단일 버스 | 이중 버스 (명령어/데이터 독립) |
| **동시 접근성** | 불가능 (순차적) | 가능 (병렬적) |
| **처리 성능** | 병목 현상으로 제한적 | 병렬 처리로 높은 성능 |
| **설계 복잡도** | 단순 | 복잡 |
| **제조 비용** | 저비용 | 고비용 |
| **메모리 효율성** | 높음 (동적 할당) | 낮음 (고정 할당) |
| **실시간성** | 예측 어려움 | 예측 가능 |
| **주요 응용분야** | 범용 컴퓨터, 서버 | 임베디드 시스템, DSP |
| **대표 사례** | x86, ARM (메인 메모리 수준) | AVR, PIC, DSP 칩 |

## 4. 수정형 하버드 구조 (Modified Harvard Architecture)

현대 고성능 CPU는 두 구조의 장점을 결합한 **수정형 하버드 구조**를 채택한다. 메인 메모리는 폰 노이만 방식을 유지하되, **캐시 계층에서 하버드 방식**을 적용하여 성능과 효율성을 동시에 확보한다.

### 핵심 개념
* **메인 메모리**: 통합 구조 (폰 노이만 방식) - 비용 효율성과 유연성 확보
* **캐시 계층**: 분리 구조 (하버드 방식) - I-Cache(명령어 캐시)와 D-Cache(데이터 캐시) 독립 운영
* **하이브리드 접근**: 캐시 히트 시 병렬 처리, 캐시 미스 시 순차 처리

### 동작 원리
1. **캐시 히트**: I-Cache와 D-Cache에서 동시에 명령어와 데이터를 가져와 병렬 처리
2. **캐시 미스**: 메인 메모리에서 순차적으로 데이터를 가져와 해당 캐시에 저장
3. **성능 최적화**: 지역성 원리를 활용하여 대부분의 경우 캐시 히트로 병렬 처리 실현

### 구조도
```
┌─────────────────────────────────────┐
│          메인 메모리 (통합)           │
│    ┌─────────────────────────────┐   │
│    │     통합 주소 공간           │   │
│    │ (명령어 + 데이터 혼재)       │   │
│    └─────────────────────────────┘   │
└─────────────────────────────────────┘
                   ↕
              [ 메모리 버스 ]
                   ↕
┌─────────────────────────────────────┐
│              CPU                    │
│ ┌─────────────┐   ┌─────────────┐   │
│ │  I-Cache    │   │  D-Cache    │   │
│ │ (명령어 캐시) │   │ (데이터 캐시) │   │
│ └─────────────┘   └─────────────┘   │
│        ↕                 ↕          │
│ ┌─────────────┐   ┌─────────────┐   │
│ │ 명령어 처리부 │   │ 데이터 처리부 │   │
│ └─────────────┘   └─────────────┘   │
│          └─────────┬─────────┘       │
│                   ALU                │
└─────────────────────────────────────┘
```

### 대표적인 구현 사례
* **x86 프로세서**: Intel, AMD CPU의 L1 캐시가 I-Cache/D-Cache로 분리
* **ARM 프로세서**: 모바일 및 임베디드 시스템에서 광범위하게 사용
* **RISC-V**: 오픈소스 아키텍처에서도 동일한 방식 채택

## 5. 실무 관점에서의 응용

### 임베디드 시스템 (전통적 하버드 구조)
* **MCU 사례**: AVR, PIC, 8051 등
* **DSP 사례**: TI C6000 시리즈, Analog Devices SHARC
* **특징**: 실시간 처리가 중요하고, 메모리 사용량이 예측 가능한 환경

### 범용 컴퓨팅 (수정형 하버드 구조)
* **데스크톱/서버**: Intel Core, AMD Ryzen
* **모바일**: ARM Cortex, Apple Silicon
* **특징**: 높은 성능과 유연성이 모두 필요한 환경

### 보안 관점
* **코드 주입 방어**: 하버드 구조의 명령어/데이터 분리는 악성 코드 실행 방지에 유리
* **NX bit**: 현대 CPU는 데이터 영역의 코드 실행을 막는 기능 제공
* **ASLR**: 주소 공간 배치 무작위화로 보안 강화

## 6. 성능 최적화 기법

### 폰 노이만 병목 완화 방법
1. **캐시 메모리**: 자주 사용되는 데이터를 고속 메모리에 저장
2. **파이프라이닝**: 명령어를 여러 단계로 나누어 동시 처리
3. **분기 예측**: 조건문의 결과를 미리 예측하여 성능 향상
4. **슈퍼스칼라**: 여러 명령어를 동시에 실행할 수 있는 구조

### 메모리 계층 구조 활용
* **레지스터** (가장 빠름) → **L1 캐시** → **L2 캐시** → **L3 캐시** → **메인 메모리** → **저장장치** (가장 느림)
* 각 계층의 지역성을 활용하여 전체적인 성능 향상

---

## 핵심 용어 정리

* **폰 노이만 병목**: 명령어와 데이터가 동일한 버스를 공유하면서 발생하는 성능 제약
* **I-Cache / D-Cache**: 명령어 전용 캐시와 데이터 전용 캐시로, 분리하여 병렬 접근 가능
* **캐시 히트/미스**: 필요한 데이터가 캐시에 있으면 히트, 없으면 미스
* **지역성 원리**: 최근 사용된 데이터나 인근 데이터가 다시 사용될 가능성이 높다는 원리
* **임베디드 시스템**: 특정 기능에 특화된 소형 컴퓨터 시스템 (냉장고, 자동차 ECU 등)
* **DSP**: 디지털 신호 처리에 최적화된 전용 프로세서
* **실시간 시스템**: 정해진 시간 내에 반드시 응답해야 하는 시스템

-----


# 1.1-3 명령어 실행 과정

## 1. 개요

CPU는 프로그램을 실행하기 위해 메모리에 저장된 명령어를 하나씩 가져와 해석하고 실행한다. 이 일련의 과정을 **명령어 사이클(Instruction Cycle)**이라 하며, 다음 세 단계로 구성된다:

1. **Fetch (인출)**
2. **Decode (해석)**
3. **Execute (실행)**

현대 고성능 CPU는 이 과정을 파이프라인 방식으로 겹쳐 처리하여 성능을 향상시킨다.

## 2. 명령어 처리 단계

### 2.1 Fetch (명령어 인출)
* **PC (Program Counter)**가 가리키는 메모리 주소에서 명령어를 읽어온다
* 읽어온 명령어를 **IR (Instruction Register)**에 저장한다
* PC는 자동으로 다음 명령어의 주소로 증가한다

### 2.2 Decode (명령어 해석)
* IR에 저장된 명령어의 **Opcode(연산 코드)**를 분석하여 수행할 동작을 결정한다
* **Operand(피연산자)** 정보를 확인하여 필요한 레지스터나 메모리 주소를 파악한다
* 제어 유닛이 해당 명령어 실행을 위한 제어 신호를 준비한다

### 2.3 Execute (명령어 실행)
* 해석된 명령어에 따라 실제 연산이나 동작을 수행한다
* 산술/논리 연산은 **ALU**가 담당하고, 데이터 이동이나 분기는 제어 유닛이 처리한다
* 실행 결과를 레지스터나 메모리에 저장한다

## 3. 명령어 실행 예시

### ADD R1, R2, R3 (R1 = R2 + R3)

**명령어 의미**: R2 레지스터와 R3 레지스터의 값을 더해서 R1 레지스터에 저장

**단계별 처리 과정**:

**1단계 - Fetch (인출)**
- PC가 현재 0x1000 주소를 가리키고 있다고 가정
- 메모리 주소 0x1000에서 "ADD R1, R2, R3" 명령어를 읽어온다
- 이 명령어를 IR에 저장한다
- PC를 0x1004로 증가시킨다 (다음 명령어 준비)

**2단계 - Decode (해석)**
- IR의 명령어를 분석한다:
  - Opcode: "ADD" → 덧셈 연산임을 파악
  - 첫 번째 피연산자: R1 → 결과를 저장할 레지스터
  - 두 번째 피연산자: R2 → 첫 번째 더할 값이 있는 레지스터  
  - 세 번째 피연산자: R3 → 두 번째 더할 값이 있는 레지스터
- 제어 유닛이 ALU에 덧셈 연산 수행 신호를 준비한다

**3단계 - Execute (실행)**
- R2에서 값을 읽어온다 (예: 값이 10이라고 가정)
- R3에서 값을 읽어온다 (예: 값이 20이라고 가정)
- ALU가 10 + 20 = 30을 계산한다
- 계산 결과 30을 R1 레지스터에 저장한다

### LOAD R1, [100] (메모리 주소 100의 값을 R1으로 로드)

**명령어 의미**: 메모리 주소 100번지에 있는 데이터를 R1 레지스터로 가져오기

**단계별 처리 과정**:

**1단계 - Fetch (인출)**
- PC가 가리키는 주소에서 "LOAD R1, [100]" 명령어를 IR로 가져온다
- PC를 다음 명령어 주소로 증가시킨다

**2단계 - Decode (해석)**
- Opcode: "LOAD" → 메모리에서 데이터를 읽어오는 명령임을 파악
- 목적지: R1 → 데이터를 저장할 레지스터
- 소스: [100] → 메모리 주소 100번지에서 데이터를 가져와야 함

**3단계 - Execute (실행)**
- 메모리 주소 100번지에 접근한다
- 해당 주소의 데이터를 읽어온다 (예: 값이 50이라고 가정)
- 읽어온 값 50을 R1 레지스터에 저장한다

## 4. 주요 레지스터

| 레지스터 | 역할 |
|----------|------|
| **PC (Program Counter)** | 다음에 실행할 명령어의 메모리 주소를 저장 |
| **IR (Instruction Register)** | 현재 처리 중인 명령어를 저장 |
| **MAR (Memory Address Register)** | 메모리 접근 시 사용할 주소를 저장 |
| **MDR (Memory Data Register)** | 메모리와 주고받을 데이터를 임시 저장 |
| **ACC (Accumulator)** | 연산 결과를 임시로 저장하는 레지스터 |

## 5. 파이프라이닝 (Pipelining)

### 등장 배경
명령어를 순차적으로 처리하면 한 번에 하나의 단계만 활용되어 CPU 자원이 비효율적으로 사용된다. 파이프라이닝은 여러 명령어의 서로 다른 단계를 동시에 처리하여 성능을 향상시키는 기법이다.

### 동작 방식
```
시간 →   1    2    3    4    5    6
명령어1: F    D    E
명령어2:      F    D    E
명령어3:           F    D    E
명령어4:                F    D    E

F=Fetch, D=Decode, E=Execute
```

### 장점
* 전체 처리량(Throughput) 향상
* CPU 내부 자원의 효율적 활용
* 이론적으로 파이프라인 단계 수만큼 성능 향상 가능

### 주요 문제점
* **데이터 해저드**: 이전 명령어의 결과를 다음 명령어가 필요로 할 때
* **제어 해저드**: 분기 명령어로 인해 실행 흐름이 바뀔 때
* **구조적 해저드**: 하드웨어 자원 부족으로 충돌이 발생할 때

### 해결 방법
* **분기 예측**: 조건 분기의 결과를 미리 예측
* **데이터 포워딩**: 이전 단계의 결과를 바로 다음 단계로 전달
* **파이프라인 스톨**: 필요시 파이프라인을 일시 정지

## 6. 명령어 사이클 흐름도

```
시작
 ↓
┌─────────────────┐
│ PC → 메모리 주소  │
│  명령어 인출     │
└────────┬────────┘
         ↓
┌─────────────────┐
│ 명령어 → IR     │
│   명령어 저장    │
└────────┬────────┘
         ↓
┌─────────────────┐
│ Opcode 분석     │
│ 피연산자 확인    │
└────────┬────────┘
         ↓
┌─────────────────┐
│ ALU/제어유닛    │
│   실제 실행     │
└────────┬────────┘
         ↓
      다음 명령어
```

---

## 핵심 용어 정리

* **명령어 사이클**: CPU가 하나의 명령어를 처리하는 전체 과정 (Fetch-Decode-Execute)
* **Opcode**: 명령어에서 수행할 연산의 종류를 나타내는 부분
* **Operand**: 연산의 대상이 되는 데이터나 주소 정보
* **Program Counter (PC)**: 다음에 실행할 명령어의 주소를 가리키는 레지스터
* **Instruction Register (IR)**: 현재 처리 중인 명령어를 저장하는 레지스터
* **파이프라이닝**: 명령어 처리 단계를 겹쳐서 병렬로 수행하는 성능 향상 기법
* **Pipeline Hazard**: 파이프라인 처리 중 발생하는 충돌이나 지연 상황



# 1.1-4 캐시 메모리와 메모리 계층 구조

## 1. 캐시 메모리란?

CPU는 매우 빠르게 연산을 수행하지만, 메모리(RAM) 접근 속도는 상대적으로 느리다. 이로 인해 병목(Bottleneck)이 발생하는데, 이를 줄이기 위해 CPU와 RAM 사이에 위치한 **고속 임시 메모리**인 **캐시(Cache)**가 사용된다.

자주 사용하는 데이터를 가까이 두면 CPU가 더 빠르게 작업 가능

## 2. 지역성(Locality)의 원리

캐시가 효과적으로 작동하는 이유는 프로그램 실행 시 데이터 접근에 일정한 **패턴(지역성)**이 있기 때문이다.

### 2.1 시간 지역성 (Temporal Locality)
* 최근 사용된 데이터는 곧 다시 사용될 가능성이 높다
* 예: `for(i=0; i<100; i++) sum += i;` ← i와 sum을 반복 사용

### 2.2 공간 지역성 (Spatial Locality)
* 접근한 데이터 주변의 데이터도 함께 사용될 가능성이 높다
* 예: `arr[0], arr[1], arr[2]...` ← 배열 순차 접근

## 3. 메모리 계층 구조

```
가깝고 빠름 (비쌈)
 ┌──────────┐
 │ Register │
 ├──────────┤
 │   Cache  │   ← L1(가장 빠름), L2, L3(용량 큼)
 ├──────────┤
 │    RAM   │
 ├──────────┤
 │ SSD/HDD  │
└──────────┘
멀고 느림 (쌈)
```

* 위로 갈수록 **속도↑**, **용량↓**, **가격↑**
* 아래로 갈수록 **속도↓**, **용량↑**, **가격↓**

### 캐시 계층별 특징
**L1, L2, L3는 Level(계층)을 의미하며, 숫자가 낮을수록 CPU에 가까움**

* **L1 캐시 (1차 캐시)**: CPU 코어에 가장 가까움, 가장 빠름, 용량 작음 (보통 32KB~64KB)
* **L2 캐시 (2차 캐시)**: 중간 거리, 중간 속도, 중간 용량 (보통 256KB~1MB)
* **L3 캐시 (3차 캐시)**: 가장 멀리, 상대적으로 느림, 용량 큼, 여러 코어가 공유 (보통 8MB~32MB)

## 4. 캐시 히트 vs 미스

| 개념 | 설명 |
|------|------|
| **히트** | 필요한 데이터가 캐시에 있어 빠르게 처리됨 |
| **미스** | 캐시에 없어서 RAM까지 접근 → 느려짐 (10-100배 느릴 수 있음) |

* **LRU (Least Recently Used)**: 가장 오래 사용하지 않은 데이터를 제거하고 새 데이터로 교체하는 방식 (간단히 언급)

## 5. 실무/면접 관점 팁

* 배열을 순차적으로 접근하면 캐시 효율이 좋아짐 (공간 지역성)
* 조건문/분기문이 많으면 캐시 미스 발생 가능성 증가
* "왜 캐시가 필요하냐?"라는 질문엔 "CPU와 메모리의 속도 차이를 완화하기 위해"라고 명확히 대답할 수 있어야 함

## 핵심 요약

| 개념 | 요약 |
|------|------|
| **캐시 메모리** | CPU와 RAM 사이 속도 차이 완충 역할 |
| **지역성 원리** | 시간/공간 접근 패턴을 활용한 효율 향상 |
| **메모리 계층** | 레지스터 > 캐시 > RAM > 저장장치 순 |
| **캐시 히트** | 빠름 (데이터가 캐시에 있음) |
| **캐시 미스** | 느림 (RAM까지 다시 가야 함, 10-100배 느려질 수 있음) |

## 5. 레지스터, ALU, 제어 유닛
- 레지스터의 역할
- 산술논리연산장치(ALU)의 기능
- 제어 유닛(Control Unit)의 역할

## 6. 입출력 시스템과 버스
- 입출력 장치 개요
- 버스의 종류: 데이터, 주소, 제어 버스
- 입출력 방식 개요: 폴링, 인터럽트, DMA