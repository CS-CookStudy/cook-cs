# 데이터 처리 파이프라인

## 1. 데이터 처리 파이프라인 개요

### 데이터 파이프라인이란?

- **데이터를 수집부터 활용까지 자동화된 흐름으로 처리**하는 시스템
- **ETL/ELT 프로세스**를 통해 원시 데이터를 분석 가능한 형태로 변환
- **실시간** 또는 **배치** 방식으로 데이터 처리
- 빅데이터와 머신러닝의 핵심 인프라

### 전통적 데이터 처리 vs 현대적 파이프라인

전통적 방식은 **수집 → 저장 → 수동 분석 → 보고서** 형태로 일회성이고 느렸습니다.
현대적 파이프라인은 **수집 → 실시간 처리 → 저장 → 분석 → 액션**으로 자동화되고 실시간으로 확장 가능합니다.

## 2. 데이터 파이프라인 구성 요소

### 데이터 수집 (Data Ingestion)

**실시간 수집:**

- 웹 클릭 스트림, IoT 센서 데이터, 소셜 미디어 피드, 금융 거래 데이터 등
- 주요 도구: Apache Kafka, Amazon Kinesis, Azure Event Hubs, Google Pub/Sub

**배치 수집:**

- 데이터베이스 백업, 로그 파일, 파일 시스템, 외부 API 등
- 주요 도구: Apache Sqoop, Talend, Informatica, Custom Scripts

### 데이터 저장 (Data Storage)

**데이터 레이크:**

- 원시 데이터를 그대로 저장하는 방식
- 스키마 온 리드(Schema-on-Read) 방식으로 저장 시점에 구조 결정 안함
- 다양한 데이터 형식 지원, 비용 효율적
- 기술: Hadoop HDFS, Amazon S3, Azure Data Lake, Google Cloud Storage

**데이터 웨어하우스:**

- 구조화된 데이터를 저장하는 방식
- 스키마 온 라이트(Schema-on-Write) 방식으로 저장 전 구조 결정
- 빠른 쿼리 성능, 높은 데이터 품질
- 기술: Amazon Redshift, Google BigQuery, Azure SQL DW, Snowflake

### 데이터 처리 (Data Processing)

**배치 처리:**

- 대용량 데이터를 주기적으로 처리 (일일 매출 분석, 월별 보고서 등)
- 주요 도구: Apache Spark, Apache Hive, Apache Pig, MapReduce

**스트림 처리:**

- 실시간으로 들어오는 데이터 처리 (실시간 추천, 이상 탐지 등)
- 주요 도구: Apache Storm, Apache Flink, Kafka Streams, Spark Streaming

## 3. ETL vs ELT 패러다임

### ETL (Extract, Transform, Load)

**Extract → Transform → Load** 순서로 처리합니다.

- 데이터 추출 → 변환 서버에서 변환 → 저장소에 적재
- 전통적 방식으로 구조화된 데이터와 데이터 웨어하우스에 적합
- 변환 후 저장하므로 저장 공간 효율적

### ELT (Extract, Load, Transform)

**Extract → Load → Transform** 순서로 처리합니다.

- 데이터 추출 → 저장소에 바로 적재 → 저장소 내에서 변환
- 현대적 방식으로 클라우드 환경에 최적화
- 원시 데이터를 먼저 저장하고 필요에 따라 변환

## 4. 배치 처리 아키텍처

### Lambda Architecture

**배치 레이어와 스피드 레이어를 병행**하는 구조입니다.

- 배치 레이어: 대용량 데이터의 정확한 처리 담당
- 스피드 레이어: 실시간 데이터의 빠른 처리 담당
- 서빙 레이어: 두 결과를 통합하여 쿼리 서비스 제공
- 장점: 높은 처리량과 낮은 지연시간
- 단점: 복잡한 아키텍처, 중복 코드 관리

### Kappa Architecture

**스트림 처리 중심**의 단순한 구조입니다.

- 모든 데이터를 스트림으로 처리
- 배치 처리가 필요하면 스트림을 재처리
- 장점: 단순한 아키텍처, 하나의 코드베이스
- 단점: 복잡한 변환에는 제한적

## 5. 실시간 데이터 처리

### Apache Kafka

**분산 스트리밍 플랫폼**으로 대용량 실시간 데이터 처리에 특화되어 있습니다.

- **Producer**: 데이터를 Kafka로 전송
- **Consumer**: Kafka에서 데이터를 읽어서 처리
- **Topic**: 데이터를 분류하는 단위
- **Partition**: Topic을 분할하여 병렬 처리 지원

특징:

- 높은 처리량 (초당 수백만 메시지)
- 내구성 보장 (데이터 복제)
- 수평 확장 가능
- 실시간 스트리밍 지원

### Apache Spark Streaming

**마이크로 배치** 방식으로 스트림 데이터를 처리합니다.

- 스트림을 작은 배치로 나누어 처리
- Spark의 배치 처리 엔진 활용
- 높은 처리량과 내결함성 제공
- SQL, ML 라이브러리와 통합 가능

## 6. 데이터 파이프라인 도구

### Apache Airflow

**워크플로우 관리 플랫폼**으로 데이터 파이프라인을 스케줄링하고 모니터링합니다.

- Python으로 DAG(Directed Acyclic Graph) 정의
- 웹 UI로 파이프라인 시각화
- 의존성 관리와 실패 처리
- 다양한 시스템과 연동 가능

### Apache NiFi

**데이터 플로우 자동화** 도구로 GUI 기반으로 데이터 파이프라인을 구성합니다.

- 드래그 앤 드롭 방식의 파이프라인 구성
- 실시간 데이터 플로우 모니터링
- 데이터 계보 추적 가능
- 백프레셔 처리 지원
