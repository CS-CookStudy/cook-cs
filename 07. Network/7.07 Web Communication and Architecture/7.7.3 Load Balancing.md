# 7.7.3 로드 밸런싱 (Load Balancing)

## 1. 정의
로드 밸런싱은 다수의 서버에 들어오는 네트워크 트래픽이나 요청을 **효율적으로 분산**하여 처리하는 기술이다.  
단일 서버에 부하가 집중되는 것을 방지하고, 서비스의 **가용성(Availability)** 과 **확장성(Scalability)** 을 보장한다.

---

## 2. 필요성
- **성능 향상**: 요청을 여러 서버로 분산 처리하여 응답 속도 개선
- **안정성 확보**: 특정 서버 장애 시 다른 서버로 트래픽 전환 (Failover)
- **확장성 보장**: 서버 수를 유연하게 늘려 서비스 확장
- **SPOF 제거**: 단일 서버 장애로 인한 전체 서비스 중단 방지

---

## 3. 기본 구조와 동작 방식
```text
[Client]
   │
   ▼
[Load Balancer] ───→ [Server1]
                   └→ [Server2]
                   └→ [Server3]
```

### 동작 과정

1. 클라이언트 요청이 로드 밸런서에 도착
2. 로드 밸런서가 서버풀(Server Pool)의 상태를 확인
3. 분산 알고리즘에 따라 적절한 서버에 요청 전달
4. 서버가 응답을 처리하여 클라이언트에게 반환

---

## 4. 특징

* **트래픽 분산**: 서버 자원의 활용도 최적화
* **고가용성 보장**: 특정 서버 장애 시 자동 우회
* **헬스 체크**: 서버 상태를 주기적으로 모니터링하여 장애 서버 자동 제외
* **유연한 확장**: 서버 증설/축소가 용이
* **보안 기능 제공**: SSL 종료(Termination), DDoS 완화 기능 일부 포함
---

## 5. 실제 활용 예시

* **웹 서비스**: Nginx, HAProxy, AWS Elastic Load Balancer(ELB)
* **클라우드 환경**: GCP Load Balancing, Azure Load Balancer
* **MSA 환경**: Kubernetes Ingress Controller, Service Mesh에서 트래픽 분산

---

## 6. 핵심 요약

* 로드 밸런싱은 **부하 분산과 장애 대응**을 통해 서비스 성능과 안정성을 확보한다.
* 단일 서버 한계를 극복하고 \*\*확장성(Scale-out)\*\*을 가능하게 한다.
* 현대 서비스 환경에서 필수적인 인프라 구성 요소이다.

---

# 7.7.3.1 L4 vs L7 로드 밸런서

## 1. 정의
로드 밸런서는 동작 계층에 따라 크게 **L4 (Transport Layer)** 와 **L7 (Application Layer)** 로 구분된다.  
OSI 7계층에서 어느 레벨의 정보를 활용해 트래픽을 분산하는지가 차이를 만든다.

---

## 2. L4 로드 밸런서 (Transport Layer)
- **동작 계층**: OSI 4계층 (TCP/UDP)
- **기준 정보**: IP 주소, 포트 번호
- **특징**
    - 패킷의 내용을 확인하지 않고 **전송 계층 정보**만으로 분산
    - 처리 속도가 빠르고 부하가 적음
    - 세션 유지(Session Persistence) 기능 제공 가능
- **예시**: AWS NLB(Network Load Balancer), LVS

---

## 3. L7 로드 밸런서 (Application Layer)
- **동작 계층**: OSI 7계층 (HTTP/HTTPS 등)
- **기준 정보**: URL, HTTP Header, Cookie 등
- **특징**
    - 애플리케이션 레벨의 요청 내용을 기반으로 분산
    - 정교한 라우팅 가능 (예: `/api/*` 요청만 특정 서버로)
    - SSL 종료(Termination), 캐싱, 압축 등 부가 기능 제공
    - 세션 유지(Session Persistence): 쿠키, URL 파라미터 등을 활용한 정교한 세션 관리
    - 상대적으로 L4보다 무겁고 성능 부담이 큼
- **예시**: Nginx, HAProxy, AWS ALB(Application Load Balancer)

---

## 4. 비교 표

| 구분 | L4 로드 밸런서 | L7 로드 밸런서 |
|------|----------------|----------------|
| **동작 계층** | 전송 계층 (TCP/UDP) | 애플리케이션 계층 (HTTP/HTTPS) |
| **분산 기준** | IP, Port | URL, Header, Cookie |
| **성능** | 가볍고 빠름 | 무겁지만 정교함 |
| **기능** | 기본적인 트래픽 분산 | 콘텐츠 기반 라우팅, 보안/최적화 기능 |
| **예시** | AWS NLB, LVS | Nginx, HAProxy, AWS ALB |

---

## 5. 핵심 요약
- **L4**: 전송 계층 기반, 빠르고 단순한 분산.
- **L7**: 애플리케이션 계층 기반, 정교한 라우팅과 부가 기능 제공.
- 서비스 요구사항에 따라 L4와 L7을 선택하거나 **혼합 사용**하기도 한다.

---

# 7.7.3.2 로드 밸런싱 알고리즘

## 1. 정의
로드 밸런싱 알고리즘은 클라이언트 요청을 여러 서버로 어떻게 분산할지 결정하는 방식이다.  
알고리즘 선택에 따라 성능, 효율성, 안정성이 달라진다.

---

## 2. 주요 알고리즘

### 1) 라운드 로빈 (Round Robin)
- 요청을 서버에 **순차적으로 분배**
- 구현 간단, 서버 성능이 비슷할 때 적합
- 서버 성능 차이가 크면 불균형 발생 가능

### 2) 가중치 라운드 로빈 (Weighted Round Robin)
- 서버 성능(가중치)에 따라 요청 분배 비율 조정
- 성능이 좋은 서버에 더 많은 요청을 할당
- 이질적인 서버 환경에 적합

### 3) 최소 연결 (Least Connection)
- 현재 **활성 연결 수가 가장 적은 서버**에 요청 분배
- 요청 처리 시간이 일정하지 않은 환경에 유리
- 트래픽이 불규칙할 때 적합

### 4) IP 해시 (IP Hash)
- 클라이언트 IP를 해싱하여 특정 서버에 매핑
- 같은 클라이언트는 항상 같은 서버로 연결 (세션 유지)
- 서버 추가/삭제 시 해시 충돌 문제 발생 가능

### 5) 랜덤 (Random)
- 서버를 무작위로 선택하여 요청 분배
- 단순하지만 예측 불가능, 부하 균형이 불안정할 수 있음

---

## 3. 비교 표

| 알고리즘 | 특징 | 장점 | 단점 | 활용 예시 |
|----------|------|------|------|-----------|
| 라운드 로빈 | 순차 분배 | 구현 단순, 균등 분배 | 서버 성능 차이 반영 불가 | 서버 스펙 균일한 웹 서버 |
| 가중치 라운드 로빈 | 성능 비례 분배 | 이질적 서버 환경 지원 | 가중치 설정 필요 | 클라우드 서버 혼합 환경 |
| 최소 연결 | 연결 수 기준 분배 | 불규칙 요청에 적합 | 연결 상태 모니터링 필요 | 동적 트래픽 서비스 |
| IP 해시 | IP 기반 매핑 | 세션 유지 용이 | 서버 증감 시 재매핑 문제 | 로그인 세션 유지 서비스 |
| 랜덤 | 무작위 분배 | 구현 단순 | 부하 불균형 위험 | 테스트, 임시 환경 |

---

## 4. 핵심 요약
- 로드 밸런싱 알고리즘은 **요청 분배 방식**을 결정하는 핵심 요소이다.
- 단순한 방식(라운드 로빈, 랜덤)부터 정교한 방식(최소 연결, IP 해시)까지 다양하다.
- 서비스 특성과 서버 환경에 맞는 알고리즘 선택이 필수적이다.
